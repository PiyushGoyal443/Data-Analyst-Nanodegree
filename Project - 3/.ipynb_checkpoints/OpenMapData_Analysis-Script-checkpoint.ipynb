{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Wrangling\n",
    "\n",
    "*By Piyush Goyal*\n",
    "\n",
    "Map Area : [Los Angeles, California](https://s3.amazonaws.com/metro-extracts.mapzen.com/los-angeles_california.osm.bz2)\n",
    "\n",
    "## Problems :\n",
    "\n",
    "\n",
    "1. Section 1: [Data Auditing and Data Cleaning](#Section-1-:-Data-auditing-and-data-cleaning)\n",
    "  * [Tag and keys count](#1.1-Tags-and-keys-counts)\n",
    "  * [Special 'tag' keys values](#1.2-Special-'tag'-keys-values)\n",
    "  * [Multiple Zip Codes](#1.3-Multiple-Zip-Codes)\n",
    "  * [Phone Numbers](#1.4-Phone-Numbers)\n",
    "  * [Street Names Abbreviated](#Street-Names-Abbreviated)\n",
    "\n",
    "\n",
    "2. Section 2: [Data Overview](#Section-2:-Data-Overview)\n",
    "  * [File Sizes](#File-Sizes)\n",
    "  * [Number of Documents](#Number-of-Documents)\n",
    "  * [Number of nodes and ways](#Number-of-nodes-and-ways)\n",
    "  * [Number of distinct users](#Number-of-distinct-users)\n",
    "  * [Top 10 Contributing Users](#Top-10-Contributing-Users)\n",
    "  * [Number of users contributing only once](#Number-of-users-contributing-only-once)\n",
    "\n",
    "\n",
    "3. Section 3: [Additional Ideas](#Section-3:-Additional-Ideas)\n",
    "  * [Contributor statistics](#Contributor-statistics)\n",
    "  * [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 : Data auditing and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf8\n",
    "# -*- coding: utf8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "import codecs\n",
    "import pymongo\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import operator\n",
    "import phonenumbers\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required variable declarations\n",
    "__JSONFILE__ = 'los-angeles_california.osm.json'\n",
    "__OSMFILE__ = 'los-angeles_california.osm'\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "address_regex = re.compile(r'^addr\\:')\n",
    "street_regex = re.compile(r'^street')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Tags and keys counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tags(osmfile):\n",
    "    tag_counts = defaultdict(int)\n",
    "    tag_keys = defaultdict(int)\n",
    "    \n",
    "    for _, element in ET.iterparse(osmfile, ('start',)):\n",
    "        tag_counts[element.tag] += 1\n",
    "        \n",
    "        if element.tag == 'tag' and 'k' in element.attrib: \n",
    "            tag_keys[element.get('k')] += 1\n",
    "\n",
    "        element.clear()\n",
    "        \n",
    "    return tag_counts, tag_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_counts, tag_keys = count_tags(__OSMFILE__)\n",
    "\n",
    "# to print the count of each tag present\n",
    "pprint(dict(tag_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to print the count of each key in 'tag' tag\n",
    "pprint(sorted(tag_keys.items(), key = operator.itemgetter(1))[::-1][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we see the top 20 of the most frequent keys occuring in 'tag' tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_key_data(osmfile, tag_keys):\n",
    "    \"\"\"\n",
    "    Parses osm file and writes the maximum of 20 data of each tag with kay-value pairs into json file\n",
    "    \"\"\"\n",
    "    data = defaultdict(set)\n",
    "    \n",
    "    tag_keys = dict(tag_keys).keys()\n",
    "    for _,element in ET.iterparse(osmfile, ('start',)):\n",
    "        if element.tag == 'note' or element.tag == 'way':\n",
    "            \n",
    "            for tag in element.iter('tag'):\n",
    "                if 'k' in tag.attrib and 'v' in tag.attrib:\n",
    "                    key = tag.get('k')\n",
    "                    if key in tag_keys and len(data[key]) < 20:\n",
    "                        data[key].add(tag.get('v'))\n",
    "        element.clear()\n",
    "    \n",
    "    #converting data so that it is json serializable\n",
    "    for key in data.keys():\n",
    "        data[key] = list(data[key])\n",
    "    \n",
    "    with open(osmfile+'-tag-key-data.json','w') as fo:\n",
    "        fo.write(json.dumps(data, indent=4)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_key_data(__OSMFILE__,tag_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the count of key occuring, to know what each key hold and what the value means, I wrote maximum of 20 values of each key into a json file. This gave insight of some inconsistant data format (like 40mph vs 40). But I leaved it as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Special 'tag' keys values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_keys_count = 0\n",
    "for key in tag_keys.keys():\n",
    "    if tag_keys[key] == 1:\n",
    "        unique_keys_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n"
     ]
    }
   ],
   "source": [
    "print unique_keys_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there were **704** tags with count equal 1 from which some were very specific while some were not necessary. So I manually made list of keys which are to be filter out before populating the databasewhich also contained some key-value tags with count more than 1 which has redundant data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Multiple Zip Codes\n",
    "\n",
    "On observing the data, the zip codes were mapped to multiple keys (eg. tiger:zip_left, tiger:zip_right, etc) and also in all some of the keys multiple zip codes were present with ';' as a delimeter. So I mapped all the zip codes to the key 'zipcodes' wich is a list of all the zipcodes observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Phone Numbers\n",
    "\n",
    "Phone numbers were formatted inconsistantly. It contained values like 'yes', so all these values were ignored and the all phone numbers were reformatted to standard form (951) 587 2505 using [phonenumbers](https://pypi.python.org/pypi/phonenumbers) module in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected = [\"Rapid\", \"Ridge\", \"Hills\", \"Bottom\", \"Union\", \"Brook\", \"Causeway\", \"Heights\", \"Station\", \"Hill\",\n",
    "            \"Branch\", \"Lodge\", \"Rue\", \"Isle\", \"Burg\", \"River\", \"Mews\", \"Views\", \"Dam\", \"Cove\", \"Brooks\",\n",
    "            \"Motorway\", \"Ways\", \"Throughway\", \"Road\", \"Ridges\", \"Path\", \"Haven\", \"Key\", \"Island\", \"Camp\", \n",
    "            \"Extensions\", \"Pine\", \"Ferry\", \"Passage\", \"Ports\", \"Spurs\", \"Ville\", \"Forges\", \"Valleys\", \"Creek\",\n",
    "            \"Terrace\", \"Alley\", \"Course\", \"Prairie\", \"Corner\", \"Mill\", \"Glen\", \"Arcade\", \"Mills\", \"Plains\",\n",
    "            \"Rest\", \"Bypass\", \"Circle\", \"Walk\", \"Circles\", \"Flat\", \"Junction\", \"Extension\", \"Park\", \"Lakes\",\n",
    "            \"Ford\", \"Orchard\", \"Grove\", \"Courts\", \"Fords\", \"Walks\", \"Cape\", \"Landing\", \"Spur\", \"Fort\",\n",
    "            \"Greens\", \"Harbor\", \"Light\", \"Plaza\", \"Coves\", \"Mall\", \"Green\", \"Islands\", \"Loop\", \"Overpass\",\n",
    "            \"Square\", \"Meadow\", \"Stream\", \"Point\", \"Pines\", \"Viaduct\", \"Shore\", \"Shoal\", \"Pass\", \"Roads\",\n",
    "            \"Place\", \"Glens\", \"Centers\", \"Row\", \"Mountain\", \"Boulevard\", \"Underpass\", \"Inlet\", \"Bayoo\",\n",
    "            \"Lights\", \"Unions\", \"Forest\", \"Way\", \"Knoll\", \"Court\", \"Stravenue\", \"Crossroad\", \"Crest\",\n",
    "            \"Meadows\", \"Tunnel\", \"Dale\", \"Mountains\", \"Keys\", \"Parkways\", \"Drives\", \"Trail\", \"Skyway\", \n",
    "            \"Pike\", \"Lane\", \"Land\", \"Center\", \"Corners\", \"Mount\", \"Ramp\", \"Points\", \"Shores\", \"Turnpike\",\n",
    "            \"Flats\", \"Parkway\", \"Plain\", \"Loaf\", \"Divide\", \"Wall\", \"Streets\", \"Hollow\", \"Locks\", \"Canyon\",\n",
    "            \"Spring\", \"Oval\", \"Avenue\", \"Junctions\", \"Vista\", \"Burgs\", \"Valley\", \"Lake\", \"Parks\", \"Field\",\n",
    "            \"Forge\", \"Expressway\", \"Beach\", \"Forks\", \"Harbors\", \"Neck\", \"Squares\", \"Garden\", \"Manor\",\n",
    "            \"Annex\", \"Club\", \"Villages\", \"Bluffs\", \"Wells\", \"Falls\", \"Highway\", \"Bluff\", \"Fall\", \"Cliff\",\n",
    "            \"Fork\", \"Knolls\", \"Fields\", \"Route\", \"Ranch\", \"Curve\", \"Drive\", \"Trafficway\", \"Freeway\",\n",
    "            \"Groves\", \"Estates\", \"Common\", \"Radial\", \"Crossing\", \"Run\", \"Summit\", \"Cliffs\", \"Manors\",\n",
    "            \"Gardens\", \"View\", \"Bridge\", \"Trace\", \"Estate\", \"Rapids\", \"Well\", \"Lock\", \"Shoals\",\n",
    "            \"Mission\", \"Port\", \"Track\", \"Street\", \"Bend\", \"Village\", \"Springs\", \"Crescent\", \"Gateway\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "        elem.clear()\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "def test():\n",
    "    st_types = audit(__OSMFILE__)\n",
    "    pprint(dict(st_types))\n",
    "    print len(st_types)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street Names Abbreviated\n",
    "\n",
    "There was too much inconsistancy in street names. So I changed all the street names to titliesed for (avenue -> Avenue). Also all '.', ',' characters were removed. Also street names like 'Telephone Ave Suite 12' are changed to 'Telephone Avenue Suite 12'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# defining varaibles\n",
    "\n",
    "CREATED_ATTRIBUTES = ['version', 'changeset', 'timestamp', 'user', 'uid']\n",
    "POSITION_ATTRIBUTES = ['lat', 'lon']\n",
    "IGNORED_TAGS = ['gnis:ST_num', 'text', 'tiger:Name', 'gnis:id', 'is_in',\n",
    "    'gnis:feature_type', 'lake:surface_area:acres', 'gnis:county_id', 'iata',\n",
    "    'stop', 'trees', 'icao', 'gnis:County', 'gnis:county_num', 'name:en', 'gnis:state_id',\n",
    "    'health_specialty:palliative_medicine', 'tiger:STATEFP', 'name:ru', 'name:uk'\n",
    "    'wikipedia:en', 'Hardware Store', 'isced', 'reg_ref', 'start_date',\n",
    "    'reg_name', 'al', 'isced:level', 'source:maxspeed', 'gnis_state_id',\n",
    "    'undefined', 'int_ref', 'source:ref:note', 'gnis:ST_alpha', 'gnis:feature_id',\n",
    "    'practice', 'lake:shore_length:miles', 'gnis:edited', 'gnis:freature_id',\n",
    "    'name:ar', 'cycleway:left', 'import_uuid', 'odbl:note', 'is_in:state',\n",
    "    'gnis:reviewed', 'name:backward', 'gnis:fcode', 'is_in:country_code',\n",
    "    'is_in:iso_3166_2', 'name:brand', 'name:pl', 'gnis:st_alpha']\n",
    "\n",
    "ALIAS_TAGS = ['name_1', 'old_name', 'alt_name', 'name_2', 'place_name', 'loc_name',\n",
    "    'official_name', 'name_3', 'short_name', 'bridge_name']\n",
    "\n",
    "ZIPCODE_TAGS = ['addr:postcode', 'tiger:zip_left', 'tiger:zip_left_1', 'tiger:zip_left_2',\n",
    "    'tiger:zip_left_3', 'tiger:zip_left_4', 'tiger:zip_right', 'tiger:zip_right_1',\n",
    "    'tiger:zip_right_2', 'tiger:zip_right_3', 'tiger:zip_right_4']\n",
    "\n",
    "MAPPED_TAGS = {'cosntruction': 'construction', 'construciton': 'construction',\n",
    "    'EXit_to': 'exit_to', 'note:ref': 'comment', 'source:note': 'source',\n",
    "    'exit_to:left': 'exit_to', 'exit_to:right': 'exit_to', 'phone': 'contact:phone',\n",
    "    'maxspeed:forward': 'maxspeed'}\n",
    "\n",
    "STREET_MAPPING = {\n",
    "           \"St\": \"Street\",\n",
    "           \"St.\": \"Street\",\n",
    "           \"ST\": \"Street\",\n",
    "           \"Sreet\" : \"Street\",\n",
    "           \"street\" : \"Street\",\n",
    "           \"Str\" : \"Street\",\n",
    "           \"road\" : \"Road\",\n",
    "           \"Roadb\" : \"Road\",\n",
    "           \"Rd\": \"Road\",\n",
    "           \"Rd.\": \"Road\",\n",
    "           \"ct.\" : \"Court\",\n",
    "           \"Ct\" : \"Court\",\n",
    "           \"Cir\" : \"Circle\",\n",
    "           \"court\" : \"Court\",\n",
    "           \"Ave\":\"Avenue\",\n",
    "           \"Av\" :\"Avenue\",\n",
    "           \"Ave\":\"Avenue\",\n",
    "           \"Ave,\":\"Avenue\",\n",
    "           \"Ave.\":\"Avenue\",\n",
    "           u\"Ave\\u200e\":\"Avenue\",\n",
    "           \"ave\":\"Avenue\",\n",
    "           \"avenue\":\"Avenue\",\n",
    "           \"Blv\" : \"Boulevard\",\n",
    "           \"Blvd\" : \"Boulevard\",\n",
    "           \"blvd\" : \"Boulevard\",\n",
    "           \"Blvd.\" : \"Boulevard\",\n",
    "           \"BLVD.\" : \"Boulevard\",\n",
    "           \"Bd.\" : \"Boulevard\",\n",
    "           \"Bl\" : \"Boulevard\",\n",
    "           \"Bl.\" : \"Boulevard\",\n",
    "           \"Dr\" : \"Drive\",\n",
    "           \"Dr.\": \"Drive\",\n",
    "           \"Ln\" : \"Lane\",\n",
    "           \"Ln.\": \"Lane\",\n",
    "           \"PL\" : \"Plaza\",\n",
    "           \"Pl\" : \"Plaza\",\n",
    "           \"Pkwy\" : \"Parkway\",\n",
    "           \"Pkwy.\" : \"Parkway\",\n",
    "           \"Pky\" : \"Parkway\",\n",
    "           \"Prkwy\" : \"Parkway\",\n",
    "           \"Rte\" : \"Route\",\n",
    "           \"Trails\" : \"Trail\",\n",
    "           \"Trl\" : \"Trail\",\n",
    "           \"way\" : \"Way\",\n",
    "           \"WAY\" : \"Way\",\n",
    "           \"Wy\" : \"Way\",\n",
    "           \"Vw\" : \"View\",\n",
    "           \"Valle\" : \"Valley\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element):\n",
    "    node = {}\n",
    "    created_attributes = CREATED_ATTRIBUTES\n",
    "    position_attributes = POSITION_ATTRIBUTES\n",
    "    ignored_tags = IGNORED_TAGS\n",
    "    alias_tags = ALIAS_TAGS\n",
    "    zipcode_tags = ZIPCODE_TAGS\n",
    "    mapped_tags = MAPPED_TAGS\n",
    "    mapping = STREET_MAPPING\n",
    "\n",
    "    if element.tag == 'node' or element.tag == 'way':\n",
    "        \n",
    "        node['type'] = element.tag\n",
    "\n",
    "        address = {}\n",
    "        zipcodes = set()\n",
    "\n",
    "        for attribute in element.attrib:\n",
    "            \n",
    "            if attribute in created_attributes:\n",
    "                \n",
    "                if 'created' not in node:\n",
    "                    node['created'] = {}\n",
    "                    \n",
    "                node['created'][attribute] = element.get(attribute)\n",
    "            elif attribute in position_attributes:\n",
    "                continue\n",
    "            else:\n",
    "                node[attribute] = element.get(attribute)\n",
    "\n",
    "        if 'lat' in element.attrib and 'lon' in element.attrib:\n",
    "            node['pos'] = [float(element.get('lat')), float(element.get('lon'))]\n",
    "\n",
    "        for child in element:\n",
    "\n",
    "            if child.tag == 'nd':\n",
    "                if 'node_refs' not in node:\n",
    "                    node['node_refs'] = []\n",
    "                if 'ref' in child.attrib:\n",
    "                    node['node_refs'].append(child.get('ref'))\n",
    "\n",
    "            if child.tag != 'tag' or 'k' not in child.attrib or 'v' not in child.attrib:\n",
    "                continue\n",
    "            key = child.get('k').lower()\n",
    "            val = child.get('v')\n",
    "\n",
    "            # skip problematic characters\n",
    "            if problemchars.search(key):\n",
    "                continue\n",
    "\n",
    "            # skip ignored tags\n",
    "            if key in ignored_tags:\n",
    "                continue\n",
    "\n",
    "            # swap keys for corrections\n",
    "            if key in mapped_tags:\n",
    "                key = mapped_tags[key]\n",
    "\n",
    "            if key in zipcode_tags:\n",
    "                for zipcode in process_zipcode(val):\n",
    "                    zipcodes.add(zipcode)\n",
    "\n",
    "            # set all states to CA\n",
    "            if key == 'addr:state':\n",
    "                key = 'CA'\n",
    "\n",
    "            # fix and standardize phone numbers using phonenumbers module and list comprehensions\n",
    "            if key == 'contact:phone':\n",
    "                phone_number_matches = [m.number for m in phonenumbers.PhoneNumberMatcher(val, \"US\")]\n",
    "                val = ';'.join([phonenumbers.format_number(phone_number_match,\n",
    "                    phonenumbers.PhoneNumberFormat.NATIONAL)\n",
    "                    for phone_number_match in phone_number_matches])\n",
    "\n",
    "            if address_regex.search(key):\n",
    "                key = key.replace('addr:', '')\n",
    "                address[key] = val\n",
    "                continue\n",
    "\n",
    "            if key in alias_tags:\n",
    "                if 'aliases' not in node:\n",
    "                    node['aliases'] = {}\n",
    "                node['aliases'][key] = val\n",
    "                continue\n",
    "\n",
    "            if ':' in key:\n",
    "                add_branched_item(key, val, node)\n",
    "                continue\n",
    "\n",
    "            if key not in node:\n",
    "                node[key] = val\n",
    "\n",
    "        if 'name' not in node and 'aliases' in node:\n",
    "            for alias in alias_tags:\n",
    "                if alias in node['aliases']:\n",
    "                    node['name'] = alias\n",
    "                    break\n",
    "\n",
    "        if zipcodes:\n",
    "            node['zipcodes'] = list(zipcodes)\n",
    "\n",
    "        if len(address) > 0:\n",
    "            node['address'] = {}\n",
    "            street_full = None\n",
    "            street_dict = {}\n",
    "            street_format = ['prefix', 'name', 'type']\n",
    "\n",
    "            for key in address:\n",
    "                val = address[key]\n",
    "                if street_regex.search(key):\n",
    "                    if key == 'street':\n",
    "                        street_full = update_name(val,mapping)\n",
    "                    elif 'street:' in key:\n",
    "                        street_dict[key.replace('street:', '')] = val\n",
    "                else:\n",
    "                    node['address'][key] = val\n",
    "\n",
    "            if street_full:\n",
    "                node['address']['street'] = street_full\n",
    "            elif len(street_dict) > 0:\n",
    "                unclean_street = ' '.join([street_dict[key] for key in street_format])\n",
    "                node['address']['street'] = update_name(unclean_street, mapping)\n",
    "\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    \n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping.keys():\n",
    "            better_name = street_type_re.sub(mapping[street_type], name)\n",
    "        \n",
    "        if street_type_in_between(name,mapping.keys()):\n",
    "            key = street_type_in_between(name,mapping.keys())\n",
    "            better_name = name.replace(key, mapping[key])\n",
    "        else:\n",
    "            better_name = name\n",
    "        return better_name\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "def street_type_in_between(val, mapping_keys):\n",
    "    \n",
    "    for key in mapping_keys:\n",
    "        if key in val:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def add_branched_item(key, val, node):\n",
    "\n",
    "    key_split = key.split(':')\n",
    "    base = key_split.pop(0)\n",
    "    remainder = ':'.join(key_split)\n",
    "    if type(node) == dict:\n",
    "        if len(key_split) == 0:\n",
    "            node[base] = val\n",
    "        else:\n",
    "            if base not in node:\n",
    "                node[base] = {}\n",
    "            add_branched_item(remainder, val, node[base])\n",
    "\n",
    "def process_zipcode(string):\n",
    "    result = []\n",
    "    groups = [group.strip() for group in string.split(';')]\n",
    "    for group in groups:\n",
    "        if re.match(r'\\d{5}\\:\\d{5}', group):\n",
    "            group_range = map(int, group.split(':'))\n",
    "            result += list(map(str, range(group_range[0], group_range[1]+1)))\n",
    "        elif re.match(r'\\d{5}', group):\n",
    "            result.append(group)\n",
    "    return result\n",
    "\n",
    "def process_map(file_in):\n",
    "    \n",
    "    file_out = '{0}.json'.format(file_in)\n",
    "    with codecs.open(file_out, 'w',encoding='utf-8') as fo:\n",
    "        print \"Writing Starts\"\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            \n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                fo.write(json.dumps(el))\n",
    "            element.clear()\n",
    "\n",
    "        print \"Writing Done\"\n",
    "\n",
    "process_map(__OSMFILE__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Section 2: Data Overview\n",
    "\n",
    "This section contains basic statistics about the dataset and the MongoDB queries used to gather them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### File Sizes\n",
    "\n",
    "los-angeles_california.osm.json : **2.5GB** <br>\n",
    "lolos-angeles_california.osm    : **2.5GB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connection = pymongo.Connection('localhost',27017)\n",
    "db = connection.OpenMapStreet\n",
    "coll = db.losAngelesCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12180466\n"
     ]
    }
   ],
   "source": [
    "print coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of nodes and ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes :  10955705\n",
      "Way :  1224761\n"
     ]
    }
   ],
   "source": [
    "print 'Nodes : ',coll.find({'type' : 'node'}).count()\n",
    "print 'Way : ',coll.find({'type' : 'way'}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of distinct users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3301\n"
     ]
    }
   ],
   "source": [
    "print len(coll.distinct('created.user'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 10 Contributing Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'ok': 1.0,\n",
      " u'result': [{u'_id': u'schleuss_imports', u'count': 1054163},\n",
      "             {u'_id': u'manings_labuildings', u'count': 635592},\n",
      "             {u'_id': u'The Temecula Mapper', u'count': 541484},\n",
      "             {u'_id': u'woodpeck_fixbot', u'count': 514697},\n",
      "             {u'_id': u'AM909', u'count': 447961},\n",
      "             {u'_id': u'kingrollo_imports', u'count': 434711},\n",
      "             {u'_id': u'nmixter', u'count': 318435},\n",
      "             {u'_id': u'N76_import', u'count': 314432},\n",
      "             {u'_id': u'SJFriedl', u'count': 263802},\n",
      "             {u'_id': u'calfarome_labuilding', u'count': 248838}],\n",
      " u'waitedMS': 0L}\n"
     ]
    }
   ],
   "source": [
    "pprint(coll.aggregate([\n",
    "        {'$group' : {'_id' : '$created.user', 'count' : {'$sum' : 1}}},\n",
    "        {'$sort' : {'count' : -1}},\n",
    "        {'$limit' : 10}\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of users contributing only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'ok': 1.0, u'result': [{u'_id': 1, u'num_users': 688}], u'waitedMS': 0L}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.aggregate([\n",
    "        {'$group' : {'_id' : '$created.user', 'count' : {'$sum' : 1}}},\n",
    "        {'$group' : {'_id' : '$count', 'num_users' : {'$sum' : 1}}},\n",
    "        {'$sort' : {'_id' : 1}},\n",
    "        {'$limit' : 1}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Additional Ideas\n",
    "\n",
    "With the queries conducted, there was more focus on the node places rather than ways. There was additional presence of relation and member tag, although auditing and analysing of those tag would have given us some more insight about the data but I left them out. \n",
    "\n",
    "Data set can be improved if a sample of data set is displayed to the users or adding regex in the form so that I would only pass the accepted format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contributor statistics\n",
    "                                                \n",
    "* Top user contribution percentage (“schleuss_imports”) : **8.65%** <br>\n",
    "* Combined top 2 users' contribution (“schleuss_imports” and “manings_labuildings”) : **13.87%**<br>\n",
    "* Combined Top 10 users contribution : **39.19%**<br>\n",
    "* Combined contribution of users contributing only once - **0.006%**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "After this review of the data it’s obvious that the **Los Angeles California** area is incomplete, though I believe it has been well cleaned for the purposes of this exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
